# S3

## Lifecycle Rules

Works with **prefixes / suffixes** and **tags**.
- **Transition Actions:** Move to X after X time.
- **Expiration Actions:** Delete after X time. *Works with old versions, incomplete multi-part uploads.*


## Storage Class Analysis

**Analyze storage access patterns to determine the most cost-effective storage** class for your data on AWS S3.  
24h to 48h to start seeing data analysis. **Only for Standard to Standard IA**.

## Requester Pays Bucket

The **owner still pays for storage**, but the **requester pays for network**.  
In a standard bucket, owner pays for both.

## Event Notifications

**Trigger an event** when an object is created, removed...  
Needs IAM permissions if you want to push events to **SNS, Lambda or SQS**.  
You can also use **EventBridge** integration to apply better filters and redirect to other AWS services.

## S3 Performance

### Baseline bucket

S3 **scales to high request rates**. **Latency is about 100-200ms**.  
We can achieve **3500 modifications** and **5500 read** operations per second per prefix.  
There are **no limits to the number of prefixes** in a bucket.

### Optimize performance

- **Multipart upload**: Recommended for files > 100MB and required for files > 5GB *(Parallelize uploads)*
- **S3 Transfer Acceleration**

### S3 Byte-Range Fetches

**Parallelize GETs** by requesting specific bytes ranges.  
Used to **speed up downloads** and **retrieve only partial data**.


## S3 Select

Retrieve less data **using simple SQL filters**. S3 will filter data **server side**.  

## S3 Batch Operations

Perform **bulk operations on existing S3 objects**.  
*Use-case: Modify metadata, encrypt data, modify TAGs, copy objects, call lambda...*

## S3 Inventory

Get a **list of all objects**.  
*Typical pipeline: S3 Inventory -> S3 Select -> S3 Batch Operations*

## S3 Storage Lens

Analyze, optimize storage **accross an entire AWS Organization**.  
Discover anomalies, identify cost efficiencies, data protection, aggregate data...  
Can export data to an S3 bucket. **Dashboard:** With metrics, customizable.

### Metrics

Free contains around 28 usage metrics, advanced metrics are paid.  
CloudWatch metrics are paid. Prefix aggregation for metrics is paid.

- **Global Metrics:** StorageBytes, ObjectCount...
- **Cost-Optimization Metrics:** NonCurrentVesitonStorageBytes, IncompleteMultipartUploadStorageBytes...
- **Data-Protection Metrics:** MFADeleteEnabledBucketCount, VersioningEnabledBucketCount...
- **Access-Management Metrics:** ObjectOwnershipBucketOwnerEnforcesBucketCount...
- **Event Metrics:** EventNotificationEnabledBucketCount...
- **Performance Metrics:** TramsferAccelerationEnabledBucketCount...
- **Activity Metrics:** AllRequests, GetRequests, BytesDownloaded...
- **Detailed Status Code Metrics:** 200OKStatusCount, 403ForbiddenErrorCount...

## S3 Object Encryption

You can use Bucket Policies to **deny bad encryption headers**.

### Server-Side Encryption

- **SSE-S3: S3 Managed Keys**: Default AES256 keys managed, owned by AWS. *x-amz-server-side-encryption: AES256*
- **SSE-KMS: KMS Keys:** Manage keys with KMS. Limitations from KMS applies (req/sec) *x-amz-server-side-encryption: aws:kms*
- **SSE-C: Customer Keys**: S3 does **not** store the encryption keys. HTTPS must be used. Keys should be provided in every header.

*Note: Only KMS decryption / encryption can be logged by CloudTrial*

## Client-Side Encryption

Client must **encrypt** data before sending to Amazon S3.  
Client must **decrypt** data after retrieving it. 

## In-Transit Encryption

Use S3 **HTTPS** protocol for SSL/TLS.  
Can be enforced with bucket policies. *aws:SecureTransport* should be true.

## Cross-Origin Resource Sharing (CORS)

Web browser mechanism to **allow requests to other origins** while visiting the main origin.  
Distant server **should allow origin server**: *Access-Control-Allow-Origin: https://web.com*  
**CORS headers can be enabled on S3**.

## MFA Delete

Force user to **use MFA** to do something important on the bucket.  
*MFA will be required to: Permanently delete an object version, suspend bucket versioning.*  
*MFA will not be required to: Enable Versioning, List deleted versions.*  
**Only root can enable / disable MFA Delete with CLI/SDK/API**

## Access Logs (Server Access Logging)

**Log all access** to S3 bucket, logged into another S3 bucket.

## Pre-Signed URL

Give **temporary access to an S3 object**. Object could be private.  
*1 min to 12h on S3 Console, 1 sec to 168 hours on CLI.*

## Glacier Vault Lock

Allow you to create undeletable objects by **locking the policy** for future edits.  
*WORM model = Write Once Read Many*

## Object Lock

Block an object version with many **retention mode**:
- **Compliance:** Can't be changed by any user or root. Retention mode and duration can't be changed
- **Governance:** Users must have special permissions to change the retention or delete the object.

They are protected for a special **retention period**.  
**Legal Hold** protect the object forever, need s3:PutObjectLegalMode permission.

## Access Points

**Access point policies** allow to give permissions for **prefixes**.  
*Example: /finance/... for Finance group users.*
Each access point has his **own DNS name** and an **access point policy**.

We can force access point to be accessible only fron **VPC**.  
You must create a **VPC Endpoint** to access the access point.  
VPC Endpoint Policy must **allow access to the target bucket and access point**.

## S3 Object Lambda

Use **Lambda Functions to change the object before it is retrieved**.  
We need an **S3 Access Point** and a **S3 Object Lambda Access Point**.  

